---
title: "OEB275r VCF and Population Structure Workshop"
author: "Tim Sackton, based from John Novembre's HGDP Population Structure Workshop"
date: "March 3rd, 2020"
output:
  html_document:
    fig_caption: yes
  pdf_document:
    fig_caption: yes
bibliography: doc/references.bib
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=6, fig.height=4, fig.path='plot/',
                      echo=TRUE, eval=FALSE, warning=TRUE, message=TRUE)


```

Run these code chunks to set up dependencies. Necessary binaries are in the bin subdirectory.
```{r eval = TRUE, echo = FALSE, warning = FALSE, message = FALSE}
library(RColorBrewer)
library(ggplot2)
library(cowplot)
library(tidyverse)
```

```{r}
tryCatch({
  library(devtools)
},error = function(err){
  install.packages("devtools")
})
tryCatch({
library(PCAviz)
},error = function(err){
  install.packages("devtools")
  devtools::install_github("NovembreLab/PCAviz",build_vignettes = FALSE)
})
```

# OEB 275r Population Structure Workshop
=======
### Introduction

[text from John Novembre]

Population structure is a commonplace feature of genetic variation data, and it has importance in numerous application areas, including evolutionary genetics, conservation genetics, and human genetics.  At a broad level, population structure is the existence of differing levels of genetic relatedness among some subgroups within a sample.  This may arise for a variety of reasons, but a common cause is that samples have been drawn from geographically isolated groups or different locales across a geographic continuum. Regardless of the cause, understanding the structure in a sample is necessary before more sophisticated analyses are undertaken. For example, to infer divergence times between two populations requires knowing two populations even exist and which individuals belong to each.  

Two of the most commonly used approaches to describe population structure in a sample are principal components analysis [@Menozzi78;@CavSforza94; @Price06;@Patterson06] and admixture proportion inference [@Pritchard00;@Novembre16a].  In brief, principal components analysis reduces a  multi-dimensional dataset to a much smaller number of dimensions that allows for visual exploration and compact quantitive summaries.  In its application to genetic data, the numerous genotypes observed per individual are reduced to a few summary coordinates. With admixture proportion inference, individuals in a sample are modeled as having a proportion of their genome derived from each of several source populations. The goal is to infer the proportions of ancestry in each source populations, and these proportions can be used to produce compact visual summaries that reveal the existence of population structure in a sample.  

The history and basic behaviors of both these approaches have been written about extentsively, including by some of us, and so we refer readers to several previous publications to learn the basic background and interpretative nuances of these approaches and their derivatives [@Pritchard00; @Falush03; @Rosenberg05; @Hubisz09; @Raj14; @Novembre14;@Falush16; @Alexander09; @Alexander11; @Price06;@Patterson06; @Novembre08a; @McVean09; @Novembre16b]. Here, in the spirit of this volume, we provide a protocol for running these analyses and share some pragmatic caveats that do not always arise in more abstract discussions regarding these methods.  

### Materials
We are going to focus today on data exploration and on running pca using the `smartpca` software developed by Nick Patterson and colleagues for carrying out PCA [@Price06]. If there is time, we may discuss the `ADMIXTURE` software that John Novembre's lab developed [@Alexander09] for efficiently estimating admixture proportions in the "Pritchard-Stephens-Donnelly" model of admixture [@Pritchard00;@Novembre16a]. For visualization, we'll use `PCAviz` [@Novembre17], a novel R package for plotting PCA outputs, and `pong` [@Behr16] for visualizing output of admixture proportion inferences. We also use `PLINK` [@Purcell07; @Chang15] as a tool to perform some basic manipulations of the data, and vcftools. Binaries for plink, smartpca, and admixture are provided; vcftools commands I will demonstrate, but we won't run. There is a module for vcftools on the Cannon cluster, if you would like to try it.

We will use example data from several different bird resequencing datas: House sparrows [@Elgvin17; @Runemark18], Great tits [@Qu15; @Laine16], and burrowing owls [@Mueller18]. Some of the processing I have already done for these datasets, but we'll do some ourselves.

### The VCF file

We will start by looking briefly at what a vcf file is. A vcf file is a way to store variant calls, that is places where resequencing data for individuals differ from the reference genome. This is a bit of a pain to do in Rstudio, but I'll share my screen and walk you through it. Everything we will work with today has already been filtered to retain just chromosome 9, for speed and efficiency. These have also been filtered with some standard site filters, to mark sites that are potentially problematic.

### Preprocessing

The first thing we want to do, before we do any 'real' analysis, is look at some metrics of data quality. In particular, we want to be sure that none of our individuals are just low quality samples. We can do this by looking at depth and missingness (the fraction of all sites that are not called in a paritcular indivdual). We might also want to calculate things like relatedness, because for all the analyses we will run today, we want to be sure to avoid using related individuals.

You can run these if you want, but this may not work if vcftools is not configured on the course VDI, and is unnecessary, as I have provided the outputs of these commands for you.

```{r, engine = 'bash', eval = FALSE}
SPECIES=pmaj

vcftools --gzvcf data/vcfs/${SPECIES}.chrom9.vcf.gz --out data/${SPECIES}/${SPECIES} --remove-indels --remove-filtered-all --missing-indv
vcftools --gzvcf data/vcfs/${SPECIES}.chrom9.vcf.gz --out data/${SPECIES}/${SPECIES} --remove-indels --remove-filtered-all --depth
vcftools --gzvcf data/vcfs/${SPECIES}.chrom9.vcf.gz --out data/${SPECIES}/${SPECIES} --remove-indels --remove-filtered-all --max-missing 0.15 --relatedness2
```

Note that is we were doing this for a real project, we'd want to script this, so we could reuse this code. Note we are using a bash variable here, ```${SPECIES}``` so we don't have to retype the vcf filename and the outputs if we do reuse this code.

This will produce three files. One that lists the missingness per individual, one that lists the depth per individual, and one that computes a pairwise relatedness matrix.

#### Missingness, Depth, and Relatedness

One of our first questions should be whether any individuals just didn't get properly sequenced. We'll define some functions to read in our vcftools outputs and make plots so that we can do this repeatedly for different species.

```{r, engine='R', eval=TRUE}

read_ind_qc <- function(species, sample_file) {
  samples <- read_tsv(sample_file)
  species_path = paste0("data/", species, "/", species)
  ind_miss <- read_tsv(paste0(species_path, ".imiss"))
  ind_depth <- read_tsv(paste0(species_path, ".idepth"))
  relate <- read_tsv(paste0(species_path, ".relatedness2"))  

  #NOTE the following line assumes that the sample_file has a column named sample, and does not do any error checking.
  #this is bad coding practice but for the purposes of this workshop shouldn't break anything because I am providing all the sample files

  ind_qc <- left_join(samples, ind_miss, by=c("sample" = "INDV")) %>% left_join(ind_depth, by=c("sample" = "INDV"))

  #this returns a named list

  return(list("qc" = ind_qc, "relate" = relate))

}

plot_ind_qc <- function(df) {
  df %>% ggplot(aes(x=F_MISS, y=MEAN_DEPTH, color=pop)) + geom_point() + scale_x_log10()
}

plot_relatedness <- function(df) {
  df %>% filter(INDV1 != INDV2) %>% mutate(relatedness = ifelse(RELATEDNESS_PHI < 0, 0, RELATEDNESS_PHI)) %>%
  ggplot(aes(x=INDV1, y=INDV2)) +
  geom_tile(aes(fill = relatedness)) +
  scale_fill_gradient(low="ivory1",high="red4") +
  theme(axis.text.y = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.ticks.x = element_blank(),
        legend.position = "top")
}

```


Now let's try this.

```{r}

pmaj<-read_ind_qc(species = "pmaj", sample_file = "data/pmaj/pmaj_samples.txt")
pmaj
```

Now we can make some plots

```{r}
plot_ind_qc(pmaj$qc)
```
Okay, now relatedness.

```{r}
plot_relatedness(pmaj$relate)
```

From the manual: "Close relatives can be inferred fairly reliably based on the estimated kinship coefficients as shown in the following simple algorithm: an estimated kinship coefficient range >0.354, [0.177, 0.354], [0.0884, 0.177] and [0.0442, 0.0884] corresponds to duplicate/MZ twin, 1st-degree, 2nd-degree, and 3rd-degree relationships respectively."

```{r}
pmaj$relate %>% filter(INDV1 != INDV2, RELATEDNESS_PHI > 0.0442)
```

For this species, we don't need to remove any individual because of relatedness. But, we are going to remove the one individual who is listed as "unknown" in our sampling, SAMN04296376. To facilitate removing individuals, we'll make a file of individuals to remove and then use that file with grep (to filter the sample information) and vcftools (to filter the vcf). We'll then export a new vcf that can be read into PLINK for further processing, filtering to retain only biallelic snps and sites with no more than 15% missing data.


```{r engine=bash, eval=FALSE}
echo "SAMN04296376" > data/pmaj/pmaj_to_remove
grep -v -f data/pmaj/pmaj_to_remove data/pmaj/pmaj_samples.txt > data/pmaj/pmaj_samples_clean.txt


vcftools --gzvcf data/vcfs/pmaj.chrom9.vcf.gz --out pmaj_clean --remove-indels --remove-filtered-all \
  --min-alleles 2 --max-alleles 2 \
  --max-missing 0.15 --remove data/pmaj/pmaj_to_remove
  --recode
```

We should also compress and index this output file.

#### Exercises

There are two more species that I've computed the vcftools output for: the burrowing owl (acun) and the house sparrow (pdom). Using the functions that we've defined -- ```read_ind_qc, plot_ind_qc, plot_relatedness`` -- take a look at these data and see if you can come up with a list of individuals that should probably be filtered from each dataset.

### Loading into PLINK and LD pruning

[text from John Novembre]

SNPs in high LD with each other contain redundant information.  More worrisome is the potential for some regions of the genome to have a disproportionate influence on the results and thus distort the representation of genome-wide structure.  A nice empirical example of the problem is in Figure 5 of Tian et al [@Tian2008aa], where PC2 of the genome-wide data is shown to be reflecting the variation in a 3.8Mb region of chromosome 8 that is known to harbor an inversion. A standard approach to address this issue is to filter out SNPs based on pairwise LD to produce a reduced set of more independent markers.  First, we'll load the cleaned vcf into PLINK format, and then we use `plink`'s commands to produce a new LD-pruned dataset.The approach considers a chromosomal window of 50 SNPs at a time, and for any pair whose genotypes have an association $r^2$ value greater than 0.1, it removes a SNP from the pair.  Then the window is shifted by 10 SNPs and the procedure is repeated.

Note that plink, although super-useful, is designed to work on human data, and we need to trick it to use it for non-human data.

**Note:** For non-human data, you need to include either the `--allow-extra-chr` flag, if you have non-numeric chromosome names, or `--chr-set` or `--autosome-num` if you have numeric chromosome names. In the latter case, the autosome number has to be higher than or equal to the largest numeric value in your chromosome set.

This step requires the VCF file, and converts it to plink format.
```{r engine=bash, eval=FALSE}
SPECIES=pmaj


bin/plink --vcf data/vcfs/${SPECIES}_clean.vcf.gz --make-bed --out data/${SPECIES}/${SPECIES} --set-missing-var-ids @:#[$SPECIES]\$1,\$2 --allow-extra-chr
```

This step does the LD pruning.
```{r engine=bash}
bin/plink --bfile data/${SPECIES}/${SPECIES} --indep-pairwise 50 10 0.1 --out data/${SPECIES}/${SPECIES} --allow-extra-chr
bin/plink --bfile data/${SPECIES}/${SPECIES} --make-bed --extract data/${SPECIES}/${SPECIES}.prune.in --out data/${SPECIES}/${SPECIES}.ld_pruned --allow-extra-chr
```

### PCA

PLINK helpfully has a PCA function that calculates a variance-standardized relationship matrix (remember our discussion of PCA from the lecture) and extracts the top 20 principal components from it.

```{r, engine = 'bash', eval = FALSE}
SPECIES=pmaj

bin/plink --bfile data/${SPECIES}/${SPECIES}.ld_pruned --pca var-wts --allow-extra-chr --out data/${SPECIES}/${SPECIES}.ld_pruned
```   


Note that this is a fairly rough first pass. For example, it is sometimes recommended to look for SNPs that are strongly influencing the PC results, as they could represent inversions or similar, and remove them. You can do this with the SNP loadings we calculated, but we won't do this today.

Now, we can look at the data and make some plots.

```{r}

read_pca <- function(species, sample_file, prefix, nPCs = 20) {
  samples <- read_tsv(sample_file)
  species_path = paste0("data/", species, "/", species, ".", prefix)
  PCA <- read_delim(paste0(species_path, ".eigenvec"),
                    trim_ws = TRUE, delim=" ",
                    col_names = c("ID", "ID2", paste0("PC",(1:nPCs)))) %>%
    select(-ID2) %>%
    full_join(samples, by=c("ID" = "sample")) %>%
    mutate(abr = abbreviate(pop, minlength=3)) %>% select(pop, ID, abr, PC1:PC20)
  eig.val <- sqrt(unlist(read.table(paste0(species_path,".eigenval")))[1:nPCs])
  sum.eig = sum(unlist(read.table(paste0(species_path,".eigenval"))))

  # Read in snp weightings matrix
  snpeigs = read.table(paste0(species_path,".eigenvec.var"))
  names(snpeigs) = c("chr", "ID","ref","alt",paste0("PC",(1:nPCs)))
  snpeigs$chr = factor(snpeigs$chr)
  rownames(snpeigs) <- snpeigs$ID
  snpeigs = select(snpeigs, -ID, -ref, -alt)

  return(list("pca" = PCA, "eigval" = eig.val, "eigsum" = sum.eig, "snpeigs" = snpeigs))
}

plot_pca <- function(df) {
  ggplot(data = df, aes(x = PC1, y = PC2, label = abr, color = abr)) + geom_text()
}
```


### Simple plots of the results

Let's try this for P. major
```{r}
pmaj.pca <- read_pca("pmaj", "data/pmaj/pmaj_samples_clean.txt", "ld_pruned")
plot_pca(pmaj.pca$pca)
```

#### Plotting PCA results with PCAviz
The PCAviz package can be found at https://github.com/NovembreLab/PCAviz. It provides a simple interface for quickly creating plots from PCA results. It encodes several best practices for plotting PCA (such as using abberviations for point characters and plotting median positions of each labelled group).

We first need to create a PCAviz object.  We use the `PCA` dataframe defined above.  Crucially, the sample IDs need to be in the next column after the actual numeric PC values.

```{r, results='hide',warning=FALSE,message=FALSE, fig.height=6,fig.width=8}
library(PCAviz)

# Build the PCAviz object
pmajPC <- pcaviz(dat = as.data.frame(select(pmaj.pca$pca, -abr)), sdev=pmaj.pca$eigval, var=pmaj.pca$eigsum, rotation = pmaj.pca$snpeigs)
```

Let's look at the default plot.

```{r, results='hide',warning=FALSE,message=FALSE, fig.height=6,fig.width=8}
plot(pmajPC, color="pop")
```

Make a series of plots:

```{r}
pcdata=pmajPC

# Customize
geom.point.summary.params = list(shape = 16,stroke = 1,size = 7,
                                 alpha = .7)
theme_local <- function () {
  theme_cowplot(font_size=10)
}

plot0 <- plot(pcdata)
plot_legend <- get_legend(plot0)

plot1 <- plot(pcdata,coords = paste0("PC",c(1,2)), color = "pop",
              geom.point.summary.params = geom.point.summary.params,
              preserve.scale = F ,show.legend = FALSE) + theme_cowplot(font_size=10)

plot2 <- plot(pcdata,coords = paste0("PC",c(3,4)), color = "pop",
              geom.point.summary.params = geom.point.summary.params,
              preserve.scale = F ,show.legend = FALSE) + theme_cowplot(font_size=10)

plot3 <- plot(pcdata,coords = paste0("PC",c(5,6)), color = "pop",
              geom.point.summary.params = geom.point.summary.params,
              preserve.scale = F ,show.legend = FALSE) + theme_cowplot(font_size=10)

plot_grid(plot1, plot2, plot3, plot_legend, labels = list("A","B","C",""))
```

The proportion of total variance explained by each PC is a useful metric for understanding structure in a sample and for evaluating how many PCs one might want to include in downstream analyses. This can be computed as  $\lambda_i / \sum_{k} \lambda_k$, with $\lambda_i$ being eigenvalues in decreasing order, and is plotted below:
```{r, warnings=FALSE,fig.width=3.25,fig.height=3}
screeplot(pmajPC,type='pve')  + ylim(0,0.25) +
      theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
      theme(axis.line = element_line(size = 1, linetype = "solid"))
```


You have the files to look at the sparrow and the owl datasets as well. As an exercise, let's explore their PC plots.

While we didn't get to it today, there are lots of other things we can do. For example, the admixture program (in the bin) directory can be used to generate admixture / STRUCTURE-style plots. It is very easy to run ```admixture data/pmaj/pmaj.ld_pruned.bed 8``` for example will generate a K=8 admixture run for the Pmaj data. It is a bit complicated to plot, but there is a detailed manual: http://dalexander.github.io/admixture/admixture-manual.pdf

You can also use PLINK to subset your data to focus on some specific individuals. For example, in the Pmaj data, we might want to exclude the two highly divergent populations and focus on the European and west Asian samples.

Let's quickly look at how to do that. We can use the ```--keep or --keep-fam``` option to filter a PLINK run to just the samples listed. Because of the way plink stores sample information (as a sample id and family id), for our data it makes sense to filter on families, which are equivalent to samples (yes, it's complicated, this is what we get for not working on humans).

First, we'll make a list of the ids that are in the populations we want to keep.

```{r}
pops_to_keep <- c("EU", "MON", "FRA", "UK", "EST", "SPA")
samples_to_keep <- pmaj$qc %>% filter(pop %in% pops_to_keep) %>% select(sample)
write_tsv(samples_to_keep, "data/pmaj/pmaj_filtered_pops", col_names = FALSE)
```

Now we can rerun the PCA with PLINK, but use the ```--keep-fam``` option to only keep the `pmaj_filtered_pops` samples.

```{r engine=bash}
SPECIES=pmaj

bin/plink --bfile data/${SPECIES}/${SPECIES}.ld_pruned --pca var-wts --allow-extra-chr --keep-fam data/${SPECIES}/${SPECIES}_filtered_pops --out data/${SPECIES}/${SPECIES}.ld_pruned
```

I hope this provides a good guideline for how to start with this kind of analysis, but remember this is just a start, and there is a lot more to explore in population structure methods.
